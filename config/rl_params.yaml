# Deep Q-Learning Parameters

# Training parameters
training:
  num_episodes: 1000 # Increased from 100 for more thorough training
  max_steps_per_episode: 500  # Increased from 200 for longer episodes
  batch_size: 128  # Increased from 64 for more stable learning
  learning_rate: 0.0001
  gamma: 0.99  # discount factor
  target_update_freq: 10  # episodes between target network updates
  
# Exploration parameters
exploration:
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 0.99  # Slower decay for more exploration
  
# Experience replay parameters
replay_buffer:
  capacity: 50000  # Increased from 10000 for more diverse experiences
  min_samples_to_learn: 1000  # Increased from 200 for more stable initial learning
  
# Neural network architecture
network:
  state_dim: 8  # [SINR, distance, velocity, current_mode, etc.]
  action_dim: 3  # [STAY, UP, DOWN]
  hidden_layers: [128, 128]  # Larger network for better learning
  activation: "relu"
  
# Evaluation parameters
evaluation:
  eval_episodes: 10  # Number of episodes for evaluation
  eval_frequency: 50  # episodes between evaluations
  save_model_frequency: 50  # episodes between model saves 